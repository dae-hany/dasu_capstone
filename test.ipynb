{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.parse import urljoin, urlparse\n",
    "import os\n",
    "\n",
    "def crawl(url, domain, visited=None):\n",
    "    if visited is None:\n",
    "        visited = set()\n",
    "\n",
    "    # 이미 방문한 URL은 다시 크롤링하지 않도록 체크\n",
    "    if url in visited:\n",
    "        return\n",
    "    visited.add(url)\n",
    "\n",
    "    print(f\"크롤링 중: {url}\")\n",
    "\n",
    "    try:\n",
    "        # HTTP GET 요청 보내기 (필요시 headers 등을 추가할 수 있음)\n",
    "        response = requests.get(url)\n",
    "        if response.status_code != 200:\n",
    "            print(f\"페이지 요청 실패: {url} (상태 코드: {response.status_code})\")\n",
    "            return\n",
    "\n",
    "        # HTML 소스 코드 가져오기\n",
    "        html_content = response.text\n",
    "\n",
    "        # BeautifulSoup으로 HTML 파싱하기\n",
    "        soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "        # 모든 <a> 태그의 href 속성 추출 (내부 링크 위주로 처리)\n",
    "        for a_tag in soup.find_all('a'):\n",
    "            href = a_tag.get('href')\n",
    "            if not href:\n",
    "                continue\n",
    "\n",
    "            # 상대 경로인 경우, 절대 URL로 변환\n",
    "            full_url = urljoin(url, href)\n",
    "            parsed_url = urlparse(full_url) \n",
    "\n",
    "            # 동일 도메인 내 링크만 처리 \n",
    "            if parsed_url.netloc == domain:\n",
    "                visited.add(full_url)\n",
    "                # 필요에 따라 재귀적으로 크롤링할 수 있음 (현재는 주석 처리)\n",
    "                # crawl(full_url, visited)\n",
    "        return list(visited)\n",
    "    except Exception as e:\n",
    "        print(f\"오류 발생: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "크롤링 중: https://sociology.jnu.ac.kr/sociology/8677/subview.do\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'https://sociology.jnu.ac.kr/bbs/sociology/1001/rssList.do?row=708'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLS = crawl(\"https://sociology.jnu.ac.kr/sociology/8677/subview.do\",\"sociology.jnu.ac.kr\")\n",
    "\n",
    "for url in URLS:\n",
    "    if \"rss\" in url:\n",
    "        rss_url = url\n",
    "        break \n",
    "\n",
    "rss_url = rss_url[ :len(rss_url) - 2] \n",
    "\"\"\"노가다\"\"\"\n",
    "number = \"708\"################################################\n",
    "rss_url = rss_url + number\n",
    "rss_url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV 및 JSON 파일 저장 완료!\n"
     ]
    }
   ],
   "source": [
    "import feedparser\n",
    "import pandas as pd\n",
    "\n",
    "feed = feedparser.parse(rss_url)\n",
    "\n",
    "\"\"\"노가다다\"\"\"\n",
    "department = \"사회학과\"######################################\n",
    "\n",
    "# 데이터를 리스트로 저장\n",
    "entries = []\n",
    "for entry in feed.entries:\n",
    "    entries.append({\n",
    "        \"학부\": department,\n",
    "        \"제목\": entry.title,\n",
    "        \"링크\": entry.link,\n",
    "        \"내용\": entry.summary,\n",
    "        \"작성일\": entry.published\n",
    "    })\n",
    "\n",
    "# 데이터프레임 변환\n",
    "df = pd.DataFrame(entries)\n",
    "\n",
    "# CSV 파일로 저장\n",
    "df.to_csv(f\"{department} rss_feed.csv\", index=False, encoding=\"utf-8-sig\")\n",
    "\n",
    "# JSON 파일로 저장\n",
    "df.to_json(f\"{department} rss_feed.json\", orient=\"records\", force_ascii=False)\n",
    "\n",
    "print(\"CSV 및 JSON 파일 저장 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dasu_capstone",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
